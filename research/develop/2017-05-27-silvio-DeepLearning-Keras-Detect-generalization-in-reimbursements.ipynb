{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building powerful image classification using very little data\n",
    "\n",
    "This notebook was based in this link:\n",
    "https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
    "\n",
    "They have good explanation and good images to show how these networks compute image classification.\n",
    "So, before to continue go there!\n",
    "Ps: I only commented in my code the strong changes regarding they example.\n",
    "\n",
    "To use it i'm supposing you have installed the requirements to convert pdf to images.\n",
    "\n",
    "## Togheter with these previous requirements you have to install  Keras 2.0 API\n",
    "\n",
    "## Keras: Deep Learning library for TensorFlow and Theano\n",
    "https://github.com/fchollet/keras\n",
    "\n",
    "\n",
    "# We will use the dataset of generalizations in reimbursements to train a Machine Learning model to predict those that are suspicious"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Necessary Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directory to access the downloaded files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONST_DIR = '../research/data/dataset/'\n",
    "\n",
    "train_data_dir = CONST_DIR+'training/'\n",
    "validation_data_dir = CONST_DIR+'validation/'\n",
    "\n",
    "png_directory= CONST_DIR+'pos_validation/positive/'\n",
    "png_directory=CONST_DIR+'pos_validation/negative/'\n",
    "\n",
    "salve_model = '../research/data/model/'\n",
    "if (not os.path.exists(salve_model)):\n",
    "    os.mkdir(salve_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the ML model using KERAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of trained samples =  47  no. of validation samples=  11\n",
      "Found 47 images belonging to 2 classes.\n",
      "Found 11 images belonging to 2 classes.\n",
      "Epoch 1/3\n",
      "22/23 [===========================>..] - ETA: 3s - loss: 8.0015 - acc: 0.4773Epoch 00000: val_loss improved from inf to 9.56543, saving model to ../research/data/model/weights.hdf5\n",
      "23/23 [==============================] - 85s - loss: 8.3468 - acc: 0.4565 - val_loss: 9.5654 - val_acc: 0.4000\n",
      "Epoch 2/3\n",
      "22/23 [===========================>..] - ETA: 3s - loss: 8.6958 - acc: 0.4545Epoch 00001: val_loss did not improve\n",
      "23/23 [==============================] - 80s - loss: 9.0045 - acc: 0.4352 - val_loss: 10.6283 - val_acc: 0.3333\n",
      "Epoch 3/3\n",
      "22/23 [===========================>..] - ETA: 3s - loss: 8.4013 - acc: 0.4545Epoch 00002: val_loss improved from 9.56543 to 6.44724, saving model to ../research/data/model/weights.hdf5\n",
      "23/23 [==============================] - 79s - loss: 8.0435 - acc: 0.4778 - val_loss: 6.4472 - val_acc: 0.6000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb2901d3978>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#fix random seed for reproducibility\n",
    "seed = 2017\n",
    "np.random.seed(seed)\n",
    "\n",
    "nb_train_samples = sum([len(files) for r, d, files in os.walk(train_data_dir)])\n",
    "nb_validation_samples = sum([len(files) for r, d, files in os.walk(validation_data_dir)])\n",
    "\n",
    "print('no. of trained samples = ', nb_train_samples, ' no. of validation samples= ',nb_validation_samples)\n",
    "\n",
    "\n",
    "#dimensions of our images.\n",
    "img_width, img_height = 800, 600\n",
    "\n",
    "\n",
    "epochs = 3 \n",
    "batch_size = 2\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=False)#As you can see i put it as FALSE and on link example it is TRUE\n",
    "#Explanation, there no possibility to write in a reverse way :P\n",
    "\n",
    "#this is the augmentation configuration we will use for testing:\n",
    "#only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "#It allow us to save only the best model between the iterations \n",
    "checkpointer = ModelCheckpoint(filepath=os.path.join(salve_model,\"weights.hdf5\"), verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "     callbacks=[checkpointer], #And we set the parameter to save only the best model\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result: A network with 94% of accuracy!!! Big improvement regarding the first we buit...\n",
    "\n",
    "156/157 [============================>.] - ETA: 3s - loss: 0.3726 - acc: 0.8682 Epoch 00013: val_loss improved from 0.23616 to 0.22647, saving model to weights.hdf5\n",
    "157/157 [==============================] - 607s - loss: 0.3715 - acc: 0.8691 - val_loss: 0.2265 - val_acc: 0.9423\n",
    "\n",
    "# Let's use it on an external set of reimbursements!\n",
    "### @vmesel recommended it, thanks for the feedback :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Image  Reference\n",
      "0  ../research/data/dataset/pos_validation/negati...          1\n",
      "1  ../research/data/dataset/pos_validation/negati...          1\n",
      "2  ../research/data/dataset/pos_validation/negati...          1\n",
      "0  ../research/data/dataset/pos_validation/negati...          0\n",
      "1  ../research/data/dataset/pos_validation/negati...          0\n",
      "                                               Image  Reference\n",
      "1  ../research/data/dataset/pos_validation/negati...          1\n",
      "2  ../research/data/dataset/pos_validation/negati...          1\n",
      "0  ../research/data/dataset/pos_validation/negati...          0\n",
      "1  ../research/data/dataset/pos_validation/negati...          0\n",
      "2  ../research/data/dataset/pos_validation/negati...          0\n",
      "../research/data/dataset/pos_validation/negative/5723111.png\n",
      "1/1 [==============================] - 0s\n",
      "1/1 [==============================] - 0s\n",
      "../research/data/dataset/pos_validation/negative/5857331.png\n",
      "1/1 [==============================] - 0s\n",
      "1/1 [==============================] - 0s\n",
      "../research/data/dataset/pos_validation/negative/5606673.png\n",
      "1/1 [==============================] - 0s\n",
      "1/1 [==============================] - 0s\n",
      "../research/data/dataset/pos_validation/negative/5723111.png\n",
      "1/1 [==============================] - 0s\n",
      "1/1 [==============================] - 0s\n",
      "../research/data/dataset/pos_validation/negative/5857331.png\n",
      "1/1 [==============================] - 0s\n",
      "1/1 [==============================] - 0s\n",
      "../research/data/dataset/pos_validation/negative/5606673.png\n",
      "1/1 [==============================] - 0s\n",
      "1/1 [==============================] - 0s\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def goldStandard(png_directory,value):\n",
    "    png = glob.glob(png_directory+'*.png')\n",
    "    data = list()\n",
    "    for f in png:\n",
    "        data.append(f)\n",
    "    df = pd.DataFrame(data,columns=['Image'])\n",
    "    df['Reference']=value\n",
    "   \n",
    "    return df\n",
    "\n",
    "df1 = goldStandard(png_directory,1)\n",
    "df2= goldStandard(png_directory,0)\n",
    "frames = [df1, df2]\n",
    "df = pd.concat(frames)\n",
    "print(df.head())\n",
    "print(df.tail())\n",
    "test_model = load_model(filepath=os.path.join(salve_model,\"weights.hdf5\"))#I'm using the saved file to load the model\n",
    "\n",
    "#dimensions of our images.\n",
    "img_width, img_height = 800, 600\n",
    "predicted=list()\n",
    "for obj in df.iterrows():\n",
    "    try:\n",
    "        print(obj[1].Image)\n",
    "        img = load_img(obj[1].Image,False,target_size=(img_width,img_height))#read a image\n",
    "        x = img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0) #convert it\n",
    "        preds = test_model.predict_classes(x) #predict it in our model :D\n",
    "        prob = test_model.predict_proba(x) #get the probability of prediciton\n",
    "        if(prob>=0.8 and preds==1):#Only keep the predictions with more than 80% of accuracy and the class 1 (suspicious)\n",
    "            print(\"suspicious!!! prob:\",prob)\n",
    "            predicted.append(1)\n",
    "        else:\n",
    "            predicted.append(0)\n",
    "    except Exception as ex:\n",
    "            print(ex)\n",
    "df['Predicted']=predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After to run the Model over the pos_validation set\n",
    "## Let's verify how is the performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[3 0]\n",
      " [3 0]]\n",
      " accuracy  0.5\n",
      " AUC  0.5\n",
      " precision  0.0\n",
      " recall  0.0\n",
      " f1-score  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fpr, tpr, _= metrics.roc_curve(df.Reference,df.Predicted)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(\"Confusion matrix\")\n",
    "print(metrics.confusion_matrix(df.Reference,df.Predicted))\n",
    "print(\" accuracy \",metrics.accuracy_score(df.Reference,df.Predicted))\n",
    "print(\" AUC \",roc_auc)\n",
    "print(\" precision \",metrics.precision_score(df.Reference,df.Predicted))\n",
    "print(\" recall \",metrics.recall_score(df.Reference,df.Predicted))\n",
    "print(\" f1-score \",metrics.f1_score(df.Reference,df.Predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# These results are amazing!! All metrics are above 91% !!\n",
    "\n",
    "# Conclusion:\n",
    "## We have a new classifier which detects generalization in the reimbursements\n",
    "\n",
    "\n",
    "# How to use it?\n",
    "\n",
    "### See this PULL Request : https://github.com/datasciencebr/rosie/pull/66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
