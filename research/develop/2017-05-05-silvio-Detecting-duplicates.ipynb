{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook aims to detect duplicate reimbursements.\n",
    "\n",
    "## To do so i took the following paper as base:\n",
    "1) B. Wang, Z. Li, M. Li and W. y. Ma, \"Large-Scale Duplicate Detection for Web Image Search,\" 2006 IEEE International Conference on Multimedia and Expo, Toronto, Ont., 2006, pp. 353-356.\n",
    "doi: 10.1109/ICME.2006.262509\n",
    "link: https://pdfs.semanticscholar.org/32fe/c74b6e319921672aa7f6ca2d2598bf92120d.pdf\n",
    "\n",
    "They are generating hash code to detect duplicate image. Thus, i found some python libraries which do the same. \n",
    "\n",
    "Dash Python library to calculate the difference hash (perceptual hash) for a given image, useful for detecting duplicates. (https://github.com/Jetsetter/dhash)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from urllib.request import urlopen\n",
    "import dhash\n",
    "from PIL import Image as pil_image\n",
    "from wand.image import Image\n",
    "from PIL import ImageFilter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to download the pdf and convert it to PNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download_doc(url_link):\n",
    "            try:\n",
    "                # Open the resquest and get the file\n",
    "                response = urlopen(url_link)\n",
    "                # Default arguments to read the file and has a good resolution\n",
    "                with Image(file=response, resolution=300) as img:\n",
    "                    img.compression_quality = 99\n",
    "                    # Chosen format to convert pdf to image\n",
    "                    with img.convert('png') as converted:\n",
    "                        # Converts the Wand image to PIL image\n",
    "                        data = pil_image.open(BytesIO(converted.make_blob()))\n",
    "                        data = data.convert('RGB')\n",
    "                        hw_tuple = (800,600)\n",
    "                        # Resizing of PIL image to fit our ML model\n",
    "                        if data.size != hw_tuple:\n",
    "                            data = data.resize(hw_tuple)\n",
    "                        return data\n",
    "            except Exception as ex:\n",
    "                print(\"Error during pdf download\")\n",
    "                print(ex)\n",
    "                # Case we get some exception we return None\n",
    "                return None\n",
    "\n",
    "def hamming2(s1, s2):\n",
    "    \"\"\"Calculate the Hamming distance between two bit strings\"\"\"\n",
    "    assert len(s1) == len(s2)\n",
    "    return sum(c1 != c2 for c1, c2 in zip(s1, s2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duplicated Reimbursement\n",
    "\n",
    "As duplicate i'm applying a BLUR filter in the downloaded reimbursement. Therefore, the reimbursement is the same, but with different image resolution!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc1 = 'http://www.camara.gov.br/cota-parlamentar/documentos/publ/2437/2015/5645173.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original\n",
    "image1 = download_doc(doc1)\n",
    "\n",
    "# Duplicate\n",
    "image2 = image1.filter(ImageFilter.BLUR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20181c1c18000000c7000c7c38000000\n",
      "30181c1c18000000c7000c7c38000000\n",
      "1\n",
      "1 bit differs out of 128 (0.8%)\n"
     ]
    }
   ],
   "source": [
    "dhash.force_pil()\n",
    "\n",
    "size = 8\n",
    "\n",
    "row, col = dhash.dhash_row_col(image1)\n",
    "hash1 = dhash.format_hex(row, col,size=size)\n",
    "print(hash1)\n",
    "row, col = dhash.dhash_row_col(image2)\n",
    "hash2 = dhash.format_hex(row, col,size=size)\n",
    "print(hash2)\n",
    "num_bits_different = hamming2(hash1, hash2)\n",
    "print(num_bits_different)\n",
    "print('{} {} out of {} ({:.1f}%)'.format(\n",
    "                num_bits_different,\n",
    "                'bit differs' if num_bits_different == 1 else 'bits differ',\n",
    "                size * size * 2,\n",
    "                100 * num_bits_different / (size * size * 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using documents which looks close, however they are different!\n",
    "\n",
    "document_ids: 5886345 and 5886361."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc1 = 'http://www.camara.gov.br/cota-parlamentar/documentos/publ/3074/2015/5886345.pdf'\n",
    "doc2 = 'http://www.camara.gov.br/cota-parlamentar/documentos/publ/3074/2015/5886361.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image1 = download_doc(doc1)\n",
    "image2 = download_doc(doc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d93bdbd71e787a009020fbdf0688fa00\n",
      "6666462f3f060e0af0ec06f879167e08\n",
      "29\n",
      "29 bits differ out of 128 (22.7%)\n"
     ]
    }
   ],
   "source": [
    "dhash.force_pil()\n",
    "\n",
    "size = 8\n",
    "\n",
    "row, col = dhash.dhash_row_col(image1)\n",
    "hash1 = dhash.format_hex(row, col,size=size)\n",
    "print(hash1)\n",
    "row, col = dhash.dhash_row_col(image2)\n",
    "hash2 = dhash.format_hex(row, col,size=size)\n",
    "print(hash2)\n",
    "num_bits_different = hamming2(hash1, hash2)\n",
    "print(num_bits_different)\n",
    "print('{} {} out of {} ({:.1f}%)'.format(\n",
    "                num_bits_different,\n",
    "                'bit differs' if num_bits_different == 1 else 'bits differ',\n",
    "                size * size * 2,\n",
    "                100 * num_bits_different / (size * size * 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion \n",
    "\n",
    "I’ve found that the dhash is great for detecting near duplicates (using a size 8 dhash with a maximum delta of 2 bits). But because of the simplicity of the algorithm, it’s not great at finding similar images or duplicate-but-cropped images – you’d need a more sophisticated image fingerprint if you want that. However, the dhash is good for finding exact duplicates and near duplicates, for example, the same image with slightly altered lighting, a few pixels of cropping, or very light photoshopping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Possible direction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I suggest to take a look in the follwing paper:\n",
    "    \n",
    "Pratim Ghosh, E. Drelie Gelasca, K.R. Ramakrisnan and B.S. Manjunath,\n",
    "“Duplicate Image Detection in Large Scale Databases”,\n",
    "Book Chapter in Platinum Jubilee Volume, Indian Statistical Institute, Kolkata, Oct. 2007.\n",
    "    \n",
    "https://vision.ece.ucsb.edu/sites/vision.ece.ucsb.edu/files/publications/pratim_2007_book.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
